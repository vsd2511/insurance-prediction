{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTfqHjGTXtcj"
      },
      "source": [
        "# Principal Component Ananlysis and Gradient Boosting Classification\n",
        "As we are provided with a high dimensional data, we perform Principal Component Analysis for Dimensionality Reduction, retaining only the necessary features for classifying data and discard the redundant features. We then feed in the results of this model to Gradient Boosting Classifier, which operates on several weak learning models, to generate a stronger model by rectifying errors in the weaker models. We further improve this approach by Hyparameter tuning, and tune the parameters of Gradient Boosting Classifier to obtain the best results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iqtio2tVOGyj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import cross_val_score\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DaVN7vGvOGyp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(      id  age          job  marital  education  balance housing loan  \\\n",
              " 0  98749   32       admin.   single  secondary       64     yes   no   \n",
              " 1  19550   45  blue-collar  married  secondary      534      no   no   \n",
              " 2  75084   45   technician  married  secondary     1477     yes   no   \n",
              " 3  65715   39   technician  married   tertiary       14      no   no   \n",
              " 4  41412   49  blue-collar   single    unknown     2222      no   no   \n",
              " \n",
              "     contact month  duration  campaign  pdays  previous poutcome  y  \n",
              " 0   unknown   may       202         2     -1         0  unknown  0  \n",
              " 1  cellular   aug       104         6     -1         0  unknown  0  \n",
              " 2  cellular   nov        75         1    132         1  failure  0  \n",
              " 3  cellular   jan       114         2     -1         0  unknown  0  \n",
              " 4   unknown   jun       114         2     -1         0  unknown  0  ,\n",
              " (40689, 16),\n",
              "      id  age          job  marital  education  balance housing loan   contact  \\\n",
              " 0  5149   42       admin.   single  secondary      734     yes   no  cellular   \n",
              " 1  6179   36       admin.   single  secondary       22     yes   no  cellular   \n",
              " 2  4846   29  blue-collar  married  secondary        0      no   no   unknown   \n",
              " 3  3676   46   management  married  secondary     1114      no   no  cellular   \n",
              " 4  4256   39   management  married   tertiary      378     yes  yes   unknown   \n",
              " \n",
              "   month  duration  campaign  pdays  previous poutcome  \n",
              " 0   apr       332         2    317         3  failure  \n",
              " 1   jul        77         5     -1         0  unknown  \n",
              " 2   may       215         1     -1         0  unknown  \n",
              " 3   jul        87         8     -1         0  unknown  \n",
              " 4   may       127         2     -1         0  unknown  ,\n",
              " (4522, 15))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df= pd.read_csv('Insurance_Train.csv')\n",
        "df1= pd.read_csv('Insurance_Test.csv')\n",
        "df.head(5), df.shape , df1.head(5), df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a5pt0oJUOGyp"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>98749</td>\n",
              "      <td>32</td>\n",
              "      <td>admin.</td>\n",
              "      <td>single</td>\n",
              "      <td>secondary</td>\n",
              "      <td>64</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>may</td>\n",
              "      <td>202</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19550</td>\n",
              "      <td>45</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>534</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>aug</td>\n",
              "      <td>104</td>\n",
              "      <td>6</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>75084</td>\n",
              "      <td>45</td>\n",
              "      <td>technician</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>1477</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>nov</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>132</td>\n",
              "      <td>1</td>\n",
              "      <td>failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65715</td>\n",
              "      <td>39</td>\n",
              "      <td>technician</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>14</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>jan</td>\n",
              "      <td>114</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41412</td>\n",
              "      <td>49</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>single</td>\n",
              "      <td>unknown</td>\n",
              "      <td>2222</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>jun</td>\n",
              "      <td>114</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40684</th>\n",
              "      <td>24953</td>\n",
              "      <td>29</td>\n",
              "      <td>technician</td>\n",
              "      <td>single</td>\n",
              "      <td>secondary</td>\n",
              "      <td>3313</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>jun</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40685</th>\n",
              "      <td>34002</td>\n",
              "      <td>59</td>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>92</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>may</td>\n",
              "      <td>139</td>\n",
              "      <td>2</td>\n",
              "      <td>350</td>\n",
              "      <td>1</td>\n",
              "      <td>failure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40686</th>\n",
              "      <td>76035</td>\n",
              "      <td>54</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>548</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>aug</td>\n",
              "      <td>520</td>\n",
              "      <td>7</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40687</th>\n",
              "      <td>61279</td>\n",
              "      <td>46</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>married</td>\n",
              "      <td>primary</td>\n",
              "      <td>258</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>may</td>\n",
              "      <td>217</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40688</th>\n",
              "      <td>60013</td>\n",
              "      <td>41</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>125</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40689 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  age          job  marital  education  balance housing loan  \\\n",
              "0      98749   32       admin.   single  secondary       64     yes   no   \n",
              "1      19550   45  blue-collar  married  secondary      534      no   no   \n",
              "2      75084   45   technician  married  secondary     1477     yes   no   \n",
              "3      65715   39   technician  married   tertiary       14      no   no   \n",
              "4      41412   49  blue-collar   single    unknown     2222      no   no   \n",
              "...      ...  ...          ...      ...        ...      ...     ...  ...   \n",
              "40684  24953   29   technician   single  secondary     3313     yes   no   \n",
              "40685  34002   59       admin.  married  secondary       92     yes   no   \n",
              "40686  76035   54  blue-collar  married  secondary      548      no   no   \n",
              "40687  61279   46  blue-collar  married    primary      258     yes   no   \n",
              "40688  60013   41     services  married  secondary        0     yes  yes   \n",
              "\n",
              "         contact month  duration  campaign  pdays  previous poutcome  \n",
              "0        unknown   may       202         2     -1         0  unknown  \n",
              "1       cellular   aug       104         6     -1         0  unknown  \n",
              "2       cellular   nov        75         1    132         1  failure  \n",
              "3       cellular   jan       114         2     -1         0  unknown  \n",
              "4        unknown   jun       114         2     -1         0  unknown  \n",
              "...          ...   ...       ...       ...    ...       ...      ...  \n",
              "40684    unknown   jun        18         3     -1         0  unknown  \n",
              "40685   cellular   may       139         2    350         1  failure  \n",
              "40686   cellular   aug       520         7     -1         0  unknown  \n",
              "40687    unknown   may       217         1     -1         0  unknown  \n",
              "40688  telephone   may       125         4     -1         0  unknown  \n",
              "\n",
              "[40689 rows x 15 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_x_train= df.iloc[:,0:15]\n",
        "df_y_train= df.iloc[:,15]\n",
        "df_x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0WfIgSn-OGyq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(      id  age  balance  duration  campaign  pdays  previous  job_admin.  \\\n",
              " 0  98749   32       64       202         2     -1         0           1   \n",
              " 1  19550   45      534       104         6     -1         0           0   \n",
              " \n",
              "    job_blue-collar  job_entrepreneur  ...  month_jun  month_mar  month_may  \\\n",
              " 0                0                 0  ...          0          0          1   \n",
              " 1                1                 0  ...          0          0          0   \n",
              " \n",
              "    month_nov  month_oct  month_sep  poutcome_failure  poutcome_other  \\\n",
              " 0          0          0          0                 0               0   \n",
              " 1          0          0          0                 0               0   \n",
              " \n",
              "    poutcome_success  poutcome_unknown  \n",
              " 0                 0                 1  \n",
              " 1                 0                 1  \n",
              " \n",
              " [2 rows x 49 columns],\n",
              " (40689, 16),\n",
              "      id  age  balance  duration  campaign  pdays  previous  job_admin.  \\\n",
              " 0  5149   42      734       332         2    317         3           1   \n",
              " 1  6179   36       22        77         5     -1         0           1   \n",
              " \n",
              "    job_blue-collar  job_entrepreneur  ...  month_jun  month_mar  month_may  \\\n",
              " 0                0                 0  ...          0          0          0   \n",
              " 1                0                 0  ...          0          0          0   \n",
              " \n",
              "    month_nov  month_oct  month_sep  poutcome_failure  poutcome_other  \\\n",
              " 0          0          0          0                 1               0   \n",
              " 1          0          0          0                 0               0   \n",
              " \n",
              "    poutcome_success  poutcome_unknown  \n",
              " 0                 0                 0  \n",
              " 1                 0                 1  \n",
              " \n",
              " [2 rows x 49 columns],\n",
              " (4522, 15))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_encoded= pd.get_dummies(df_x_train)\n",
        "df1_encoded= pd.get_dummies(df1)\n",
        "df_encoded.head(2), df.shape , df1_encoded.head(2), df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xvTfNSnoOGyq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(pandas.core.frame.DataFrame,\n",
              " (40689, 49),\n",
              "         id   age  balance  duration  campaign  pdays  previous  job_admin.  \\\n",
              " 0  98749.0  32.0     64.0     202.0       2.0   -1.0       0.0         1.0   \n",
              " 1  19550.0  45.0    534.0     104.0       6.0   -1.0       0.0         0.0   \n",
              " \n",
              "    job_blue-collar  job_entrepreneur  ...  month_jun  month_mar  month_may  \\\n",
              " 0              0.0               0.0  ...        0.0        0.0        1.0   \n",
              " 1              1.0               0.0  ...        0.0        0.0        0.0   \n",
              " \n",
              "    month_nov  month_oct  month_sep  poutcome_failure  poutcome_other  \\\n",
              " 0        0.0        0.0        0.0               0.0             0.0   \n",
              " 1        0.0        0.0        0.0               0.0             0.0   \n",
              " \n",
              "    poutcome_success  poutcome_unknown  \n",
              " 0               0.0               1.0  \n",
              " 1               0.0               1.0  \n",
              " \n",
              " [2 rows x 49 columns],\n",
              " pandas.core.frame.DataFrame,\n",
              " (4522, 49),\n",
              "        id   age  balance  duration  campaign  pdays  previous  job_admin.  \\\n",
              " 0  5149.0  42.0    734.0     332.0       2.0  317.0       3.0         1.0   \n",
              " 1  6179.0  36.0     22.0      77.0       5.0   -1.0       0.0         1.0   \n",
              " \n",
              "    job_blue-collar  job_entrepreneur  ...  month_jun  month_mar  month_may  \\\n",
              " 0              0.0               0.0  ...        0.0        0.0        0.0   \n",
              " 1              0.0               0.0  ...        0.0        0.0        0.0   \n",
              " \n",
              "    month_nov  month_oct  month_sep  poutcome_failure  poutcome_other  \\\n",
              " 0        0.0        0.0        0.0               1.0             0.0   \n",
              " 1        0.0        0.0        0.0               0.0             0.0   \n",
              " \n",
              "    poutcome_success  poutcome_unknown  \n",
              " 0               0.0               0.0  \n",
              " 1               0.0               1.0  \n",
              " \n",
              " [2 rows x 49 columns],\n",
              " 0        0.0\n",
              " 1        0.0\n",
              " 2        0.0\n",
              " 3        0.0\n",
              " 4        0.0\n",
              "         ... \n",
              " 40684    0.0\n",
              " 40685    0.0\n",
              " 40686    1.0\n",
              " 40687    0.0\n",
              " 40688    0.0\n",
              " Name: y, Length: 40689, dtype: float64)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = df_encoded.astype(float)\n",
        "data_y = df_y_train.astype(float)\n",
        "data_test = df1_encoded.astype(float)\n",
        "type(data) , data.shape , data.head(2), type(data_test), data_test.shape , data_test.head(2), data_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5SLEgkIpOGyr"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((40689, 49), (4522, 49))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train= data.values\n",
        "data_train_y= data_y.values\n",
        "data_test = data_test.values\n",
        "data_train.shape , data_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oflEh297OGyr"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((40689, 48),\n",
              " (40689,),\n",
              " (4522, 48),\n",
              " array([[ 32.,  64., 202.,   2.,  -1.,   0.,   1.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
              "           1.,   0.,   0.,   0.,   1.,   1.,   0.,   0.,   0.,   1.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   1.],\n",
              "        [ 45., 534., 104.,   6.,  -1.,   0.,   0.,   1.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
              "           1.,   0.,   0.,   1.,   0.,   1.,   0.,   1.,   0.,   0.,   0.,\n",
              "           1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   1.]]),\n",
              " array([0., 0., 0., ..., 1., 0., 0.]),\n",
              " array([[ 42., 734., 332.,   2., 317.,   3.,   1.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
              "           1.,   0.,   0.,   0.,   1.,   1.,   0.,   1.,   0.,   0.,   1.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           1.,   0.,   0.,   0.],\n",
              "        [ 36.,  22.,  77.,   5.,  -1.,   0.,   1.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
              "           1.,   0.,   0.,   0.,   1.,   1.,   0.,   1.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "           0.,   0.,   0.,   1.]]))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train , y_train = data_train[:,1:], data_train_y\n",
        "x_test = data_test[:,1:]\n",
        "x_train.shape, y_train.shape, x_test.shape, x_train[:2], y_train, x_test[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaTnUoQsPEuF"
      },
      "source": [
        "# Principal Component Analysis\n",
        "Principal Component Analysis involves the orthogonal projection of data onto a lower dimensional linear subspace, such that variance of the projected data is maximized. Mathematical approaches to maximize variance, leads us to the conclusion that the data needs to be projected onto the, say, top-k eigenvectors corresponding to top-k largest eigenvalues of the data covariance matrix. We find that this lower dimensional representation of data is sufficient to accurately classify data, and the rest of the features can be safely discarded, thus removing reduntancy and improving efficiency. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-wkY0ZnrOGyr"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(40689, 20)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pca = PCA(n_components=20)\n",
        "\n",
        "pca.fit(data_train)\n",
        "\n",
        "train_pca = pca.transform(data_train)\n",
        "train_pca.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dA0HHuTpOGys"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4522, 20)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pca = PCA(n_components=20)\n",
        "\n",
        "pca.fit(data_test)\n",
        "\n",
        "test_pca = pca.transform(data_test)\n",
        "test_pca.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmPK83XXOg63"
      },
      "source": [
        "# Gradient Boosting Classifier \n",
        "The Principal idea behind this algorithm is to build models sequentially, where the subsequent models try to reduce the errors of the previous models. \n",
        "To understand it better, say we feed in the observations to an initial model assuming all observations have equal weights or probabilities. This model is bound to have less accuracy and a lot of misclassifications due to the assumption that all features have equal probabilities. Now, based on these misclassifications, we feed in the observation to a second model with updated weights; i.e. we increase the weights of wrongely classified observations and decrease the weights of correctly classified ones. The same procedure is repeated till we minimize error to get a model with higher accuracy. \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The loss function for this algorithm is given as: \\\\\n",
        "\\begin{align}\n",
        "L= -Σ_{i=1}^n [y_ilog(p) + (1-y_i)log(1-p)] \n",
        "\\end{align}\n",
        "\\begin{align}\n",
        "L= -[y^*log(p) + (1-y^*)log(1-p)] \n",
        "\\end{align}\n",
        "\\begin{align}\n",
        "L= -y^*log(odds) + log(1-e^{log(odds)}) \n",
        "\\end{align}\n",
        "Now, differentiating w.r.t. *log(odds)* : \\\\\n",
        "\\begin{align}\n",
        "\\frac{dL}{d[log(odds)]}= -y + p = Prediction - Observation\n",
        "\\end{align}\n",
        "\\begin{align}\n",
        "Residual= Observation - Prediction \n",
        "\\end{align}\n",
        "\\\n",
        "A decision tree is constructed to forecast the estimated residuals, where the value of each leaf is updated as:\n",
        "\\begin{align}\n",
        "γ = \\frac{Σ_{i=1}^n Residual_i}{Σ_{i=1}^nPreviousProbability_i*(1-PreviousProbability_i)}\n",
        "\\end{align}\n",
        "\\\n",
        "Then,the log forecast for each training set instance is obtained and transformed into a probability. The new predictions are obtained as:\n",
        "\\begin{align}\n",
        "New Prediction= Previous Prediction + (Learning Rate * Prediction Residual Value)\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vQj8_8CrOGys"
      },
      "outputs": [],
      "source": [
        "def gbm(number_of_estimators,learn_rate,subsample):\n",
        "    number_of_estimators=int(number_of_estimators)\n",
        "    subsample=subsample \n",
        "    return GradientBoostingClassifier(\n",
        "    n_estimators=number_of_estimators,  # Number of estimators (trees) to use\n",
        "    learning_rate=learn_rate,  # Learning rate for updates\n",
        "    subsample=subsample,  # Subsample ratio for training each tree\n",
        "    random_state=42  # Random seed for reproducibility) \n",
        "    ).fit(train_pca, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzcbFVJ8UHur"
      },
      "source": [
        "# Hyperparameter Tuning using Bayesian Optimization\n",
        "We implement Bayesian optimization, which is a type of probabilistic optimization algorithm used to find the optimal hyperparameters for a machine learning model. In this specific case, the code optimizes hyperparameters for gradient boosting classifier.\n",
        "\n",
        "The objective_function is defined as the function that takes the hyperparameters (learning_rate, n_estimators, and subsample) and returns the mean F1 score obtained by performing cross-validation with those hyperparameters on the training data. The F1 score is a metric that combines precision and recall, and it is often used in classification tasks to evaluate the performance of a model. The pbounds dictionary specifies the ranges for the hyperparameters.The BayesianOptimization class from the bayes_opt module is used to optimize the hyperparameters. \n",
        "\n",
        "Finally, the best hyperparameters and the maximum F1 score achieved are printed using the max attribute of the optimizer object. This dictionary can be used to train the final gradient boosting classifier with the optimal hyperparameters and to evaluate its performance on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "211dJqicOGyt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | learni... | n_esti... | subsample |\n",
            "-------------------------------------------------------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m optimizer \u001b[39m=\u001b[39m BayesianOptimization(f\u001b[39m=\u001b[39mobjective_function, pbounds\u001b[39m=\u001b[39mpbounds, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[39m# Optimize hyperparameters for maximum F1 score\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m optimizer\u001b[39m.\u001b[39;49mmaximize(init_points\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, n_iter\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[0;32m     23\u001b[0m \u001b[39m# Print best hyperparameters and maximum F1 score\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(optimizer\u001b[39m.\u001b[39mmax)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:311\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    309\u001b[0m     x_probe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuggest(util)\n\u001b[0;32m    310\u001b[0m     iteration \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 311\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobe(x_probe, lazy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bounds_transformer \u001b[39mand\u001b[39;00m iteration \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    314\u001b[0m     \u001b[39m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[0;32m    315\u001b[0m     \u001b[39m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_bounds(\n\u001b[0;32m    317\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bounds_transformer\u001b[39m.\u001b[39mtransform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_space))\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:208\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_queue\u001b[39m.\u001b[39madd(params)\n\u001b[0;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_space\u001b[39m.\u001b[39;49mprobe(params)\n\u001b[0;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch(Events\u001b[39m.\u001b[39mOPTIMIZATION_STEP)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\bayes_opt\\target_space.py:236\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    234\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_as_array(params)\n\u001b[0;32m    235\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_keys, x))\n\u001b[1;32m--> 236\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constraint \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister(x, target)\n",
            "Cell \u001b[1;32mIn[12], line 10\u001b[0m, in \u001b[0;36mobjective_function\u001b[1;34m(learning_rate, n_estimators, subsample)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective_function\u001b[39m(learning_rate, n_estimators, subsample):\n\u001b[0;32m      2\u001b[0m     \u001b[39m# Define gradient boosting classifier with specified hyperparameters\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     clf \u001b[39m=\u001b[39m GradientBoostingClassifier(learning_rate\u001b[39m=\u001b[39mlearning_rate,\n\u001b[0;32m      4\u001b[0m                                      n_estimators\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(n_estimators),\n\u001b[0;32m      5\u001b[0m                                     \u001b[39m#  max_depth=int(max_depth),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m                                     \u001b[39m#  min_samples_leaf=int(min_sl),\u001b[39;00m\n\u001b[0;32m      9\u001b[0m                                      random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     f1_scores \u001b[39m=\u001b[39m cross_val_score(clf, train_pca, y_train, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mf1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     11\u001b[0m     \u001b[39m# Return mean F1 score as optimization target\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(f1_scores)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:538\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[0;32m    537\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[0;32m    539\u001b[0m     X,\n\u001b[0;32m    540\u001b[0m     y,\n\u001b[0;32m    541\u001b[0m     raw_predictions,\n\u001b[0;32m    542\u001b[0m     sample_weight,\n\u001b[0;32m    543\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[0;32m    544\u001b[0m     X_val,\n\u001b[0;32m    545\u001b[0m     y_val,\n\u001b[0;32m    546\u001b[0m     sample_weight_val,\n\u001b[0;32m    547\u001b[0m     begin_at_stage,\n\u001b[0;32m    548\u001b[0m     monitor,\n\u001b[0;32m    549\u001b[0m )\n\u001b[0;32m    551\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:615\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    608\u001b[0m     old_oob_score \u001b[39m=\u001b[39m loss_(\n\u001b[0;32m    609\u001b[0m         y[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    610\u001b[0m         raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    611\u001b[0m         sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    612\u001b[0m     )\n\u001b[0;32m    614\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[0;32m    616\u001b[0m     i,\n\u001b[0;32m    617\u001b[0m     X,\n\u001b[0;32m    618\u001b[0m     y,\n\u001b[0;32m    619\u001b[0m     raw_predictions,\n\u001b[0;32m    620\u001b[0m     sample_weight,\n\u001b[0;32m    621\u001b[0m     sample_mask,\n\u001b[0;32m    622\u001b[0m     random_state,\n\u001b[0;32m    623\u001b[0m     X_csc,\n\u001b[0;32m    624\u001b[0m     X_csr,\n\u001b[0;32m    625\u001b[0m )\n\u001b[0;32m    627\u001b[0m \u001b[39m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:257\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    254\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m    256\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[1;32m--> 257\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, residual, sample_weight\u001b[39m=\u001b[39;49msample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    259\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[0;32m    260\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    261\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[0;32m    262\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[0;32m    270\u001b[0m )\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def objective_function(learning_rate, n_estimators, subsample):\n",
        "    # Define gradient boosting classifier with specified hyperparameters\n",
        "    clf = GradientBoostingClassifier(learning_rate=learning_rate,\n",
        "                                     n_estimators=int(n_estimators),\n",
        "                                    #  max_depth=int(max_depth),\n",
        "                                     subsample=subsample,\n",
        "                                    #  min_samples_split=int(min_ss),\n",
        "                                    #  min_samples_leaf=int(min_sl),\n",
        "                                     random_state=42)\n",
        "    f1_scores = cross_val_score(clf, train_pca, y_train, cv=5, scoring='f1')\n",
        "    # Return mean F1 score as optimization target\n",
        "    return np.mean(f1_scores)\n",
        "\n",
        "# Define bounds for hyperparameters to optimize\n",
        "pbounds = {'learning_rate': (0.01, 0.1),\n",
        "           'n_estimators': (100, 1000),\n",
        "           'subsample': (0.5, 1.0),}\n",
        "# Initialize Bayesian optimization instance with objective function and bounds\n",
        "optimizer = BayesianOptimization(f=objective_function, pbounds=pbounds, random_state=42)\n",
        "\n",
        "# Optimize hyperparameters for maximum F1 score\n",
        "optimizer.maximize(init_points=5, n_iter=20)\n",
        "# Print best hyperparameters and maximum F1 score\n",
        "print(optimizer.max)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDlEtn8kOGyu"
      },
      "source": [
        "| 1         | 0.4851    | 0.04371   | 955.6     | 0.866     |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "c7V_8iL7OGyw"
      },
      "outputs": [],
      "source": [
        "y_pred=gbm(956, 0.04371, 0.866).predict(test_pca)\n",
        "type(y_pred), test_pca.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhcSCoQ4OGyx"
      },
      "outputs": [],
      "source": [
        "y_pred= y_pred.astype(float)\n",
        "y_pred= y_pred.astype(int)\n",
        "y_pred_f= y_pred.reshape(-1,1)\n",
        "y_pred_f, y_pred_f.shape, type(y_pred_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqGI-RNSOGyx"
      },
      "outputs": [],
      "source": [
        "data_f= df1.to_numpy()\n",
        "data_f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_dgJR-EOGyx"
      },
      "outputs": [],
      "source": [
        "array1_str = [list(map(str, sublist)) for sublist in data_f[:,:1]]\n",
        "array2_str = [list(map(str, sublist)) for sublist in y_pred_f]\n",
        "\n",
        "result = [array1_str[i] + array2_str[i] for i in range(len(array1_str))]\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfIKDmEhOGyy"
      },
      "outputs": [],
      "source": [
        "result= np.array(result)\n",
        "result, type(result), result.shape, data_f.shape, data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd4J_SfjOGyy"
      },
      "outputs": [],
      "source": [
        "x_desired = result.tolist()\n",
        "x_desired, type(x_desired)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iw-pBii8OGyz"
      },
      "outputs": [],
      "source": [
        "head_result = [['id','y']]\n",
        "x_desired_final= head_result+x_desired\n",
        "x_desired_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPkvPpBkOGyz"
      },
      "outputs": [],
      "source": [
        "filename = 'result_gbm.csv'\n",
        "\n",
        "# Write the processed array to the CSV file\n",
        "with open(filename, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(x_desired_final)\n",
        "\n",
        "print(f'Successfully wrote to {filename}.')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
